{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5471e151-fc94-4bcc-8222-4a1f7d1b19cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7585, 384])\n",
      "torch.Size([29905, 384])\n",
      "(191582, 2)\n",
      "(95883, 2)\n",
      "   userID  itemID\n",
      "0       6     175\n",
      "1      25     445\n",
      "2      24      28\n",
      "3      21     353\n",
      "4      32     477\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_path = \"../../data/jeehoshin/foodcom_dataset/\"\n",
    "\n",
    "user_pt = torch.load(data_path + \"user_embedding.pt\")\n",
    "item_pt = torch.load(data_path + \"item_embedding.pt\")\n",
    "\n",
    "user_embedding = nn.Embedding(user_pt['weight'].shape[0], user_pt['weight'].shape[1]).to(device)\n",
    "item_embedding = nn.Embedding(item_pt['weight'].shape[0], item_pt['weight'].shape[1]).to(device)\n",
    "user_embedding.load_state_dict(user_pt)\n",
    "item_embedding.load_state_dict(item_pt)\n",
    "\n",
    "print(user_embedding.weight.shape)\n",
    "print(item_embedding.weight.shape)\n",
    "\n",
    "df = pd.read_csv(data_path + \"foodcom.inter\", sep='\\t')\n",
    "train_interaction = df[df['x_label'] == 0][['userID', 'itemID']]\n",
    "test_interaction = df[df['x_label'] == 2][['userID', 'itemID']]\n",
    "print(train_interaction.shape)\n",
    "print(test_interaction.shape)\n",
    "\n",
    "print(train_interaction.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649bcd3-3790-4255-acec-bfc01d9a505c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7585 29905\n",
      "A done (fast)\n",
      "torch.Size([37490, 37490])\n",
      "1hop embedding\n",
      "torch.Size([7585, 384])\n",
      "torch.Size([29905, 384])\n",
      "1hop embeddings saved.\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "n_users = user_embedding.weight.shape[0]\n",
    "n_items = item_embedding.weight.shape[0]\n",
    "max_layers = 3\n",
    "\n",
    "print(n_users, n_items)\n",
    "\n",
    "# Extract user and item IDs as NumPy arrays\n",
    "user_ids = train_interaction['userID'].to_numpy()\n",
    "item_ids = train_interaction['itemID'].to_numpy()\n",
    "\n",
    "# Create interaction edges (user→item and item→user)\n",
    "row = np.concatenate([user_ids, item_ids + n_users])\n",
    "col = np.concatenate([item_ids + n_users, user_ids])\n",
    "data = np.ones(len(row), dtype=np.float32)\n",
    "\n",
    "# Create symmetric adjacency matrix A as COO\n",
    "A = sp.coo_matrix((data, (row, col)), shape=(n_users + n_items, n_users + n_items))\n",
    "\n",
    "print('A done (fast)')\n",
    "\n",
    "# Compute normalized adjacency matrix L = D^(-0.5) * A * D^(-0.5)\n",
    "sumArr = np.array(A.sum(axis=1)).flatten() + 1e-7\n",
    "diag = np.power(sumArr, -0.5)\n",
    "D = sp.diags(diag)\n",
    "L = D @ A @ D  # Matrix multiplication\n",
    "\n",
    "# Convert to PyTorch sparse tensor\n",
    "L = sp.coo_matrix(L)\n",
    "indices = torch.from_numpy(np.vstack((L.row, L.col)).astype(np.int64))\n",
    "values = torch.from_numpy(L.data.astype(np.float32))\n",
    "SparseL = torch.sparse_coo_tensor(indices, values, size=torch.Size(L.shape)).to(device)\n",
    "\n",
    "print(SparseL.shape)\n",
    "\n",
    "all_embeddings = torch.cat([user_embedding.weight, item_embedding.weight], 0).to(device)\n",
    "embeddings_list = [all_embeddings]\n",
    "scores = []\n",
    "\n",
    "user_all_embeddings = all_embeddings[:n_users, :]\n",
    "item_all_embeddings = all_embeddings[n_users:, :]\n",
    "\n",
    "for i in range(max_layers):\n",
    "    all_embeddings = torch.sparse.mm(SparseL, all_embeddings)\n",
    "    embeddings_list.append(all_embeddings)\n",
    "    lightgcn_all_embeddings = torch.stack(embeddings_list, dim=1)\n",
    "    lightgcn_all_embeddings = torch.mean(lightgcn_all_embeddings, dim=1)\n",
    "    user_all_embeddings = lightgcn_all_embeddings[:n_users, :]\n",
    "    item_all_embeddings = lightgcn_all_embeddings[n_users:, :]\n",
    "\n",
    "    print(f\"{i+1}hop embedding\")\n",
    "    print(user_all_embeddings.shape)\n",
    "    print(item_all_embeddings.shape)\n",
    "    torch.save({\"weight\": user_all_embeddings.cpu()}, data_path + f\"user_embedding_{i+1}hop.pt\")\n",
    "    torch.save({\"weight\": item_all_embeddings.cpu()}, data_path + f\"item_embedding_{i+1}hop.pt\")\n",
    "    print(f\"{i+1}hop embeddings saved.\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
