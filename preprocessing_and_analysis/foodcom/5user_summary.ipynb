{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ce70e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "11.8\n",
      "cuda\n",
      "True\n",
      "0\n",
      "<function get_device_name at 0x7f7d182205e0>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,2,3'\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72950ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29943\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2999</td>\n",
       "      <td>3567</td>\n",
       "      <td>2000-10-23</td>\n",
       "      <td>5</td>\n",
       "      <td>I have made this pie instead of plain ol' pump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2178</td>\n",
       "      <td>3704</td>\n",
       "      <td>2000-10-30</td>\n",
       "      <td>3</td>\n",
       "      <td>Careful not to cook it too long... you want th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2178</td>\n",
       "      <td>4366</td>\n",
       "      <td>2000-11-04</td>\n",
       "      <td>5</td>\n",
       "      <td>if you like oysters, this is a great alternati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5523</td>\n",
       "      <td>7695</td>\n",
       "      <td>2001-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>I agree.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42189</td>\n",
       "      <td>4460</td>\n",
       "      <td>2001-02-12</td>\n",
       "      <td>5</td>\n",
       "      <td>I have had this before. It has really good fla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428496</th>\n",
       "      <td>2001513060</td>\n",
       "      <td>367414</td>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>1</td>\n",
       "      <td>maybe I did something wrong , but I thought th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428497</th>\n",
       "      <td>2001513060</td>\n",
       "      <td>192495</td>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a keeper. Delicious Soup that both my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428498</th>\n",
       "      <td>454804</td>\n",
       "      <td>20713</td>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>0</td>\n",
       "      <td>Made this as gifts. Did 6, quart jars plus had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428499</th>\n",
       "      <td>1290903</td>\n",
       "      <td>131607</td>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a great recipe for a nice thin crispy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428500</th>\n",
       "      <td>226867</td>\n",
       "      <td>363072</td>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>5</td>\n",
       "      <td>Leaping Lizards, Lori! These are wonderful! I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428501 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id  recipe_id        date  rating  \\\n",
       "0             2999       3567  2000-10-23       5   \n",
       "1             2178       3704  2000-10-30       3   \n",
       "2             2178       4366  2000-11-04       5   \n",
       "3             5523       7695  2001-02-01       1   \n",
       "4            42189       4460  2001-02-12       5   \n",
       "...            ...        ...         ...     ...   \n",
       "428496  2001513060     367414  2018-12-17       1   \n",
       "428497  2001513060     192495  2018-12-17       5   \n",
       "428498      454804      20713  2018-12-17       0   \n",
       "428499     1290903     131607  2018-12-18       5   \n",
       "428500      226867     363072  2018-12-18       5   \n",
       "\n",
       "                                                   review  \n",
       "0       I have made this pie instead of plain ol' pump...  \n",
       "1       Careful not to cook it too long... you want th...  \n",
       "2       if you like oysters, this is a great alternati...  \n",
       "3                                                I agree.  \n",
       "4       I have had this before. It has really good fla...  \n",
       "...                                                   ...  \n",
       "428496  maybe I did something wrong , but I thought th...  \n",
       "428497  This is a keeper. Delicious Soup that both my ...  \n",
       "428498  Made this as gifts. Did 6, quart jars plus had...  \n",
       "428499  This is a great recipe for a nice thin crispy ...  \n",
       "428500  Leaping Lizards, Lori! These are wonderful! I ...  \n",
       "\n",
       "[428501 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = '../../data/jeehoshin/foodcom_dataset/'\n",
    "model_path = \"../../data/jeehoshin/huggingface\"\n",
    "\n",
    "raw_interaction = pd.read_csv(data_path + 'RAW_interactions.csv')\n",
    "pp_recipe = pd.read_csv(data_path + 'PP_recipes.csv')\n",
    "raw_recipe = pd.read_csv(data_path + 'RAW_recipes.csv')\n",
    "\n",
    "records_removed = True\n",
    "df = raw_interaction[raw_interaction['recipe_id'].isin(pp_recipe['id'].tolist())]\n",
    "while records_removed:\n",
    "    user_counts = df['user_id'].value_counts()\n",
    "    item_counts = df['recipe_id'].value_counts()\n",
    "\n",
    "    valid_users = user_counts[user_counts >= 5].index\n",
    "    valid_items = item_counts[item_counts >= 5].index\n",
    "\n",
    "    filtered_df = df[df['user_id'].isin(valid_users) & df['recipe_id'].isin(valid_items)]\n",
    "\n",
    "    if len(filtered_df) == len(df):\n",
    "        records_removed = False\n",
    "    else:\n",
    "        records_removed = True\n",
    "\n",
    "    df = filtered_df\n",
    "    \n",
    "core_inter = df\n",
    "sort_filter_ui = core_inter.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "file_names = os.listdir(data_path + 'images/')\n",
    "\n",
    "finish_image = [int(os.path.splitext(file_name)[0]) for file_name in file_names]\n",
    "sort_filter_ui = sort_filter_ui[sort_filter_ui['recipe_id'].isin(finish_image)].reset_index(drop=True)\n",
    "print(len(finish_image))\n",
    "sort_filter_ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d97b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"# of recipes with images: {len(file_names)}\")\n",
    "\n",
    "users = sort_filter_ui['user_id'].unique().tolist()\n",
    "items = sort_filter_ui['recipe_id'].unique().tolist()\n",
    "print(f\"number of users: {len(users)}, number of items: {len(items)}\")\n",
    "\n",
    "train_ = sort_filter_ui[:int(0.6*len(sort_filter_ui))]\n",
    "valid_ = sort_filter_ui[int(0.6*len(sort_filter_ui)):int(0.7*len(sort_filter_ui))]\n",
    "test_ = sort_filter_ui[int(0.7*len(sort_filter_ui)):]\n",
    "\n",
    "u_tr = set(train_['user_id'].tolist())\n",
    "u_va = set(valid_['user_id'].tolist())\n",
    "u_te = set(test_['user_id'].tolist())\n",
    "u_total = u_tr & u_te\n",
    "\n",
    "filter_u_tr = train_[train_['user_id'].isin(u_total)].reset_index(drop=True)\n",
    "filter_u_te = test_[test_['user_id'].isin(u_total)].reset_index(drop=True)\n",
    "filter_u_va = valid_[valid_['user_id'].isin(u_total)].reset_index(drop=True)\n",
    "print(f\"train interaction count : {len(filter_u_tr)}, valid interaction count : {len(filter_u_va)}, test interaction count : {len(filter_u_te)}\")\n",
    "\n",
    "u_train = set(filter_u_tr['user_id'].tolist())\n",
    "u_test = set(filter_u_te['user_id'].tolist())\n",
    "u_valid = set(filter_u_va['user_id'].tolist())\n",
    "print(f\"train user count : {len(u_train)}, valid user count : {len(u_valid)}, test user count : {len(u_test)}\")\n",
    "\n",
    "i_tr = set(filter_u_tr['recipe_id'].tolist())\n",
    "i_te = set(filter_u_te['recipe_id'].tolist())\n",
    "i_va = set(filter_u_va['recipe_id'].tolist())\n",
    "print(f\"train item count : {len(i_tr)}, valid item count : {len(i_va)}, test item count : {len(i_te)}\")\n",
    "\n",
    "i_total = i_tr|i_va|i_te\n",
    "print(f\"total user count : {len(u_total)}\")\n",
    "print(f\"total item count : {len(i_total)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interaction = filter_u_tr\n",
    "test_interaction = filter_u_te\n",
    "valid_interaction = filter_u_va\n",
    "print(f\"train interaction  : {len(train_interaction)}, valid interaction count : {len(valid_interaction)}, test interaction count : {len(test_interaction)}\")\n",
    "print(train_interaction.columns)\n",
    "print(test_interaction.columns)\n",
    "print(valid_interaction.columns)\n",
    "\n",
    "recipe_processed = raw_recipe[raw_recipe['id'].isin(i_total)].reset_index(drop=True)\n",
    "print(f\"total recipe count : {len(recipe_processed)}\")\n",
    "print(recipe_processed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e0849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe summary loaded & user review dataframe created\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "short_recipe_summaries = pd.read_csv(data_path + 'short_recipe_summaries.csv')\n",
    "recipe_summaries = {id : (name, summary) for id, name, summary\n",
    "                    in zip(short_recipe_summaries['id'], short_recipe_summaries['name'], short_recipe_summaries['summary'])}\n",
    "\n",
    "# gather 10 most recent reviews for each user in the training set\n",
    "user_reviews = defaultdict(list)\n",
    "for i in range(len(train_interaction)):\n",
    "    user_id = int(train_interaction['user_id'].iloc[i])\n",
    "    recipe_id = int(train_interaction['recipe_id'].iloc[i])\n",
    "    review = train_interaction['review'].iloc[i]\n",
    "    user_reviews[user_id].append((recipe_id, review))\n",
    "\n",
    "for user in user_reviews:\n",
    "    if len(user_reviews[user]) > 10:\n",
    "        user_reviews[user] = {recipe_id : review for recipe_id, review in user_reviews[user][-10:]}\n",
    "    else:\n",
    "        user_reviews[user] = {recipe_id : review for recipe_id, review in user_reviews[user]}\n",
    "\n",
    "user_reviews_df = pd.DataFrame(list(user_reviews.items()), columns=['user_id', 'reviews'])\n",
    "print(\"recipe summary loaded & user review dataframe created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a2e189-5aca-4b09-9148-16d825aefddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews_df.to_csv(data_path + \"user_reviews_dict.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86650384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9376073fe0584c96a491d2bb42941d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating summaries: 100%|██████████| 1897/1897 [7:27:56<00:00, 14.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import gc\n",
    "\n",
    "cache_dir = model_path\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir=cache_dir,\n",
    "    padding_side='left'\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "max_memory = {\n",
    "    0: \"40GB\",\n",
    "    1: \"40GB\",\n",
    "    2: \"40GB\",\n",
    "}\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir=cache_dir,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    max_memory=max_memory\n",
    ")\n",
    "\n",
    "# Extract summary\n",
    "def extract_summary_with_tags(text):\n",
    "    match = re.search(r\"Summarize the user's dietary preferences in 2–3 well-written sentences. assistant(.*)\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return text.strip()       \n",
    "        \n",
    "# Build prompts for batch\n",
    "def build_prompts(batch_rows):\n",
    "    prompts, valid_indices = [], []\n",
    "    for idx, row in batch_rows.iterrows():\n",
    "        try:\n",
    "            review_list = row['reviews']\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        segments = []\n",
    "        for recipe_id, review in review_list.items():\n",
    "            try:\n",
    "                recipe_id = int(recipe_id)\n",
    "                if recipe_id in recipe_summaries:\n",
    "                    name, summary = recipe_summaries[recipe_id]\n",
    "                    segments.append(f\"Recipe {len(segments) + 1}:\\n- Name: {name}\\n- Summary: {summary}\\n- User Review: {review}\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if segments:\n",
    "            recipe_info = \"\\n\\n\".join(segments)\n",
    "            prompt = (f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a nutrition-focused culinary analyst. You will be given a list of recipes along with user-written reviews.\n",
    "\n",
    "Your goal is to analyze the user's dietary preferences by identifying patterns in:\n",
    "- Ingredients and preparation styles mentioned in the recipe summaries\n",
    "- Tone and content of the user reviews\n",
    "- Patterns in cuisine, dietary concerns, or cooking techniques\n",
    "\n",
    "Use this information to infer the user's food preferences.\n",
    "                      \n",
    "{recipe_info}\n",
    "\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Summarize the user's dietary preferences in 2–3 well-written sentences. <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "    )\n",
    "            \n",
    "            prompts.append(prompt)\n",
    "            valid_indices.append(idx)\n",
    "    return prompts, valid_indices\n",
    "\n",
    "\n",
    "# Generate summaries in batches\n",
    "def generate_batch_summaries(df, batch_size=8):\n",
    "    all_summaries = [\"\"] * len(df)\n",
    "    for i in tqdm(range(0, len(df), batch_size), desc=\"Generating summaries\"):\n",
    "        batch = df.iloc[i:i + batch_size]\n",
    "        prompts, valid_indices = build_prompts(batch)\n",
    "        if not prompts:\n",
    "            continue\n",
    "        \n",
    "        inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True).to(device)      \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=200,\n",
    "                do_sample=False,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "        decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        summaries = [extract_summary_with_tags(text) for text in decoded]\n",
    "\n",
    "        for idx, summary in zip(valid_indices, summaries):\n",
    "            all_summaries[idx] = summary\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    return all_summaries\n",
    "\n",
    "# Apply batch generation\n",
    "user_preference = generate_batch_summaries(user_reviews_df, batch_size=4)\n",
    "user_reviews_df['summary'] = user_preference\n",
    "print('Summaries generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58b286fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id                                            reviews  \\\n",
      "0     2999  {3567: 'I have made this pie instead of plain ...   \n",
      "1     6836  {136026: 'I love spinach & feta cheese, so I f...   \n",
      "2     6702  {536: 'The corn dog casserole tasted a lot lik...   \n",
      "3     6512  {32147: 'SUPER SUPPER!!!!! This was an excelle...   \n",
      "4     7802  {73939: 'Easy to make and everyone loved it. I...   \n",
      "\n",
      "                                             summary  \n",
      "0  Based on the user's reviews and recipe prefere...  \n",
      "1  Based on the user's reviews, it appears that t...  \n",
      "2  Based on the user's reviews and preferences, i...  \n",
      "3  Based on the user reviews, it appears that thi...  \n",
      "4  Based on the user's reviews and recipe prefere...  \n",
      "   user_id                                            summary\n",
      "0     2999  Based on the user's reviews and recipe prefere...\n",
      "1     6836  Based on the user's reviews, it appears that t...\n",
      "2     6702  Based on the user's reviews and preferences, i...\n",
      "3     6512  Based on the user reviews, it appears that thi...\n",
      "4     7802  Based on the user's reviews and recipe prefere...\n",
      "Summaries generated and saved.\n"
     ]
    }
   ],
   "source": [
    "# Save result\n",
    "print(user_reviews_df.head())\n",
    "user_reviews_df.drop(columns=['reviews'], inplace=True)\n",
    "\n",
    "print(user_reviews_df.head())\n",
    "user_reviews_df.to_csv(data_path + \"user_summaries.csv\", index=False)\n",
    "print(\"Summaries generated and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f95a92-f443-48f1-9158-250c7d8e6179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id                                            summary\n",
      "0        2999  Based on the user's reviews and recipe prefere...\n",
      "1        6836  Based on the user's reviews, it appears that t...\n",
      "2        6702  Based on the user's reviews and preferences, i...\n",
      "3        6512  Based on the user reviews, it appears that thi...\n",
      "4        7802  Based on the user's reviews and recipe prefere...\n",
      "...       ...                                                ...\n",
      "7580   808500  Based on the user's review, it appears that th...\n",
      "7581   894666  Based on the user's review, it appears that th...\n",
      "7582  1185443  Based on the recipe and review, it appears tha...\n",
      "7583  1186221  Based on the recipe and review, it appears tha...\n",
      "7584  1185804  Based on the user's review, it appears that th...\n",
      "\n",
      "[7585 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "generated_user_preference = pd.read_csv(data_path + \"user_summaries.csv\")\n",
    "print(generated_user_preference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
